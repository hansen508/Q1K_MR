{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ac8f6e-a2c6-40de-85d7-10ac991ef006",
   "metadata": {},
   "source": [
    "# Prep steps:\n",
    "## To incorporate new data:\n",
    "1. **Log in to [REDCap Q1K Project](https://tacc-redcap.bic.mni.mcgill.ca/redcap_v13.1.27/index.php?pid=78&__record_cache_complete=1)**\n",
    "2. **Export reports** (*last done Mar 17, 2025*)\n",
    "    1. Click name of report from lefthand side:\n",
    "         - #16 - MR acquisition + feedback\n",
    "         - #20 - MR Demographics\n",
    "    2. Click button \"Export Data\"\n",
    "    3. Choose export format:\n",
    "         - MR acquisition + feedback (export as **LABELS**)\n",
    "         - MR Demographics (export as **RAW DATA**)\n",
    "    4. Click \"Export Data\"\n",
    "    5. Click Excel CSV icon to download\n",
    "    6. Click \"Close\"\n",
    "3. **Move reports from Downloads folder to this script's directory**:\n",
    "   `/export02/data/heatherh/Q1K/scripts/`\n",
    "4. **Update list of BIC DICOM directories**\n",
    "   - In terminal, run `/export02/data/heatherh/Q1K/scripts/get_DICOM_dirs.sh`\n",
    "   \n",
    "## To align participant IDs (only need to do once):\n",
    "4. **Create Record ID lookup table**       (*last done Jan 20, 2025*)\n",
    "    - Copy and paste \"Record ID\" column from REDCap \"Record Status Dashboard\" into a text file\n",
    "    - Delete \"Record ID\" heading\n",
    "   \n",
    "\n",
    "---\n",
    "# Run code:\n",
    "## SETUP\n",
    "Set paths, read in csv/txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d46399d0-5181-4a2d-8f93-d916f87908e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install natsort #run this if natsort is not installed\n",
    "from natsort import natsorted\n",
    "import statistics\n",
    "print('All packages ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e98c83b7-00d2-4f00-bd59-239284e63a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR Acquisition File: /export02/data/heatherh/Q1K/scripts/Q1KDatabase-MRAcquisitionFeedbac_DATA_LABELS_2025-03-17_2017.csv\n",
      "MR Demographics File: /export02/data/heatherh/Q1K/scripts/Q1KDatabase-MRDemographics_DATA_2025-03-17_2020.csv\n",
      "Sub Lookup Table: /export02/data/heatherh/Q1K/scripts/REDCap_RecordID_CustomLabels.txt\n",
      "BIC Sub List: /export02/data/heatherh/Q1K/scripts/Q1K_dicom_dirs.txt\n"
     ]
    }
   ],
   "source": [
    "# Import all relevant .csv/.txt files\n",
    "scriptPath='/export02/data/heatherh/Q1K/scripts/'\n",
    "os.chdir(scriptPath)\n",
    "scriptDir=os.getcwd()\n",
    "files=os.listdir(scriptDir)\n",
    "\n",
    "reportAcq='*Q1KDatabase-MRAcquisition*'\n",
    "reportDem='*Q1KDatabase-MRDemographics_DATA_2*'\n",
    "subListName='*REDCap_RecordID_CustomLabels.txt' \n",
    "subListBIC='Q1K_dicom_dirs.txt'\n",
    "\n",
    "filePathsAcq=glob.glob(scriptDir+'/'+reportAcq) \n",
    "filePathsDem=glob.glob(scriptDir+'/'+reportDem) \n",
    "filePathsSub=glob.glob(scriptDir+'/'+subListName) \n",
    "filePathBIC=glob.glob(scriptDir+'/'+subListBIC)[0] \n",
    "\n",
    "# If multiple downloads, choose the most recent (sorted in reverse chronological by default)\n",
    "if len(filePathsAcq)>1:\n",
    "    filePathAcq=filePathsAcq[-1]\n",
    "else: \n",
    "    filePathAcq=filePathsAcq[0]\n",
    "if len(filePathsDem)>1:\n",
    "    filePathDem=filePathsDem[-1]\n",
    "else: \n",
    "    filePathDem=filePathsDem[0]\n",
    "if len(filePathsSub)>1:\n",
    "    filePathSub=filePathsSub[-1]\n",
    "else: \n",
    "    filePathSub=filePathsSub[0]\n",
    "\n",
    "print('MR Acquisition File:',filePathAcq)\n",
    "print('MR Demographics File:',filePathDem)\n",
    "print('Sub Lookup Table:',filePathSub)\n",
    "print('BIC Sub List:',filePathBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621d56e-2d21-4e1e-83cc-eab8d7b64355",
   "metadata": {},
   "source": [
    "## ORGANIZE MR INFO\n",
    "Format MR acquisitions, demographics, etc. into tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d091f5ca-9439-46de-9752-ac4f3384e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataAcq size: (94, 32)\n",
      "Raw dataDem size: (2505, 11)\n"
     ]
    }
   ],
   "source": [
    "# Bring report data into Python array\n",
    "# Acquisition Data\n",
    "data_temp=[] \n",
    "with open(filePathAcq,newline='') as reportFileAcq:\n",
    "    rawDataAcq=csv.reader(reportFileAcq,delimiter=',')\n",
    "    for row in rawDataAcq:\n",
    "        data_temp.append(row)\n",
    "dataAcq=np.array(data_temp[0])  \n",
    "#print('Headers:',dataAcq)\n",
    "for row in data_temp[1:]:\n",
    "    dataAcq=np.vstack([dataAcq,row])\n",
    "print('Raw dataAcq size:',dataAcq.shape)\n",
    "\n",
    "#Demographic Data\n",
    "data_temp=[] \n",
    "with open(filePathDem,newline='') as reportFileDem:\n",
    "    rawDataDem=csv.reader(reportFileDem,delimiter=',')\n",
    "    for row in rawDataDem:\n",
    "        data_temp.append(row)\n",
    "dataDem=np.array(data_temp[0])    \n",
    "#print('Headers:',dataDem)\n",
    "for row in data_temp[1:]:\n",
    "    dataDem=np.vstack([dataDem,row])\n",
    "print('Raw dataDem size:',dataDem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e6feeae1-3be9-43df-91e6-abc94c19a185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataAcq size: (93, 32)\n",
      "Clean dataDem size: (983, 11)\n",
      "            0                       1             2             3   \\\n",
      "0    record_id       redcap_event_name  mri_birthday  enr2_pro_dob   \n",
      "1            2            intake_arm_3    1978-08-02                 \n",
      "2            2         mri_visit_arm_3                               \n",
      "3            2  retest_mri_visit_arm_3                               \n",
      "4            4            intake_arm_3    2012-08-17                 \n",
      "..         ...                     ...           ...           ...   \n",
      "978   530-3010            intake_arm_1                  2010-08-16   \n",
      "979   530-3011            intake_arm_1                  1975-11-06   \n",
      "980   530-3012            intake_arm_1                  1979-01-04   \n",
      "981   530-3013            intake_arm_1                  2008-06-18   \n",
      "982   530-3014            intake_arm_1                  1977-09-02   \n",
      "\n",
      "              4             5              6              7   \\\n",
      "0    enrlmnt_sex  enr2_pro_sex  eeg_diagnosis  gt_cnv_status   \n",
      "1              1                                               \n",
      "2                                                              \n",
      "3                                                              \n",
      "4                                                              \n",
      "..           ...           ...            ...            ...   \n",
      "978                          2                                 \n",
      "979                          2                                 \n",
      "980                          1                                 \n",
      "981                          1                                 \n",
      "982                          1                                 \n",
      "\n",
      "                     8                  9                     10  \n",
      "0     mrichecklist_file  mrichecklist_date  eeg_participant_code  \n",
      "1                                                                 \n",
      "2       Q1K_Control_ID2         2023-03-21                        \n",
      "3    Q1K_Control_ID2_RT         2023-03-29                        \n",
      "4                                                                 \n",
      "..                  ...                ...                   ...  \n",
      "978                                                               \n",
      "979                                                               \n",
      "980                                                               \n",
      "981                                                               \n",
      "982                                                               \n",
      "\n",
      "[983 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean up data of blank/unwanted rows\n",
    "rowsToRemoveAcq=[]\n",
    "for iRow in range(0,len(dataAcq)):\n",
    "    testCols=dataAcq[iRow,2:]\n",
    "    if (not any(testCols)) or ('Irini' in dataAcq[iRow,0]) or ('SCORING' in dataAcq[iRow,0]) or ('TEST' in dataAcq[iRow,0]): #Outputs True if any data exist, or False if all blank\n",
    "        rowsToRemoveAcq.append(iRow)\n",
    "dataAcqClean=np.delete(dataAcq,rowsToRemoveAcq,axis=0)\n",
    "print('Clean dataAcq size:',dataAcqClean.shape)\n",
    "#print(dataAcqClean[:,0])\n",
    "#print(pd.DataFrame(dataAcqClean))\n",
    "\n",
    "rowsToRemoveDem=[]\n",
    "for iRow in range(0,len(dataDem)):\n",
    "    testCols=dataDem[iRow,2:]\n",
    "    if (not any(testCols)) or ('Irini' in dataDem[iRow,0]) or ('SCORING' in dataDem[iRow,0]) or ('TEST' in dataDem[iRow,0]): #Outputs True if any data exist, or False if all blank\n",
    "        rowsToRemoveDem.append(iRow)\n",
    "dataDemClean=np.delete(dataDem,rowsToRemoveDem,axis=0)\n",
    "print('Clean dataDem size:',dataDemClean.shape)\n",
    "print(pd.DataFrame(dataDemClean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be2a0304-82c3-44f2-a322-7a966a8a7fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0                     1    2     3   4\n",
      "0          21       Q1K_MHC_20021_P  MHC  0021   P\n",
      "1          40       Q1K_HSJ_10040_P  HSJ  0040   P\n",
      "2          41      Q1K_HSJ_10040_M1  HSJ  0040  M1\n",
      "3          42       Q1K_MHC_20042_P  MHC  0042   P\n",
      "4          43       Q1K_HSJ_10043_P  HSJ  0043   P\n",
      "..        ...                   ...  ...   ...  ..\n",
      "462  529-4024   Q1K_OIM_4529-4024_P  OIM  4024   P\n",
      "463  529-4025  Q1K_OIM_4529-4024_M1  OIM  4024  M1\n",
      "464  529-4026   Q1K_OIM_4529-4026_P  OIM  4026   P\n",
      "465  529-4027  Q1K_OIM_4529-4026_M1  OIM  4026  M1\n",
      "466  529-4028  Q1K_OIM_4529-4026_F1  OIM  4026  F1\n",
      "\n",
      "[467 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read in Record ID Lookup Table\n",
    "data_temp=[] \n",
    "with open(filePathSub,newline='') as subLookupFile:\n",
    "    rawDataSub=csv.reader(subLookupFile,delimiter=',')\n",
    "    for row in rawDataSub:\n",
    "        row_temp=row[0] #allows string to be split\n",
    "        row_new=row_temp.split(' ')\n",
    "        IDparts_temp=row_new[2]\n",
    "        IDparts=IDparts_temp.split('_')\n",
    "        if len(IDparts) > 1: # a few records don't have IDs (so show as '' [len=1])\n",
    "            data_temp.append([row_new[0],row_new[2],IDparts[1],IDparts[2][-4:],IDparts[3]])\n",
    "\n",
    "subLookup=pd.DataFrame(data_temp)\n",
    "print(subLookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8696ff9f-7630-4e02-b895-2630e5a36e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MR scans: 97\n",
      "Number of Q1K subs with MR: 68\n",
      "Record IDs of Q1K subs with MR: ['21' '42' '43' '45' '62' '65' '66' '78' '83' '84' '87' '88' '89' '104'\n",
      " '106' '107' '120' '121' '122' '128' '146' '152' '153' '171' '174' '175'\n",
      " '177' '178' '179' '180' '181' '182' '204' '205' '219' '222' '223' '231'\n",
      " '232' '233' '234' '244' '256' '257' '265' '298' '525-1003' '525-1009'\n",
      " '525-1010' '525-1011' '525-1028' '525-1029' '525-1030' '525-1031'\n",
      " '525-1045' '525-1046' '525-1047' '525-1048' '525-1052' '525-1054'\n",
      " '525-1055' '525-1068' '525-1069' '525-1073' '525-1083' '525-1109'\n",
      " '525-1110' '525-1111']\n"
     ]
    }
   ],
   "source": [
    "# Extract which subs have MR data\n",
    "MRsubIDs=[]\n",
    "for iRow in range(1,len(dataDemClean)):\n",
    "    MRdate=dataDemClean[iRow,9]\n",
    "    if any(MRdate): #Outputs True if any data exist, or False if all blank\n",
    "        MRsubID=dataDemClean[iRow,0]\n",
    "        # Make all Record IDs 3 digits long for sorting by padding with zeros if necessary\n",
    "        #if len(MRsubID) < 3:\n",
    "        #    MRsubID = MRsubID.zfill(3)\n",
    "        #else:\n",
    "        #    MRsubID = MRsubID[-4:]    \n",
    "        MRsubIDs.append(MRsubID)\n",
    "#print('Record IDs:',MRsubIDs)\n",
    "print('Number of MR scans:',len(MRsubIDs))\n",
    "MRsubs_temp=np.unique(MRsubIDs)\n",
    "#print('Number of unique MR scans (Q1K + pilot):',len(MRsubs_temp))\n",
    "\n",
    "# Compare MR subs to Q1K IDs [translated from chatgpt)\n",
    "MRsubIdx = []\n",
    "for MRsub in MRsubs_temp:\n",
    "    subIdx = subLookup.index[subLookup.iloc[:, 0] == MRsub].tolist()\n",
    "    if subIdx:  # If subIdx is not empty\n",
    "        MRsubIdx.extend(subIdx)\n",
    "\n",
    "MRsubsInfo_temp = pd.concat([subLookup.iloc[[0], :], subLookup.loc[MRsubIdx, :]]) # Extract rows based on MRsubIdx\n",
    "MRsubsInfo = MRsubsInfo_temp.iloc[1:, :].values #remove header/row labels\n",
    "MRsubsInfo = np.array(natsorted(MRsubsInfo)) #sorts by record ID incorporating numeric magnitude (e.g., 21 < 104)\n",
    "#print(MRsubsInfo)\n",
    "#MRsubsInfo = MRsubsInfo[MRsubsInfo[:,3].argsort()] #sort by subID [note: better to sort by record ID]\n",
    "MRsubs = MRsubsInfo[:, 0] # Extract first column without header\n",
    "\n",
    "print('Number of Q1K subs with MR:',len(MRsubs))\n",
    "print('Record IDs of Q1K subs with MR:',MRsubs)\n",
    "#print('MR sub info:',MRsubsInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "432e849f-dd56-49c2-847b-e93e8d069b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   RecordID                 SubID    Age Sex Diag_behav Diag_gene Gene_copy  \\\n",
      "1         21       Q1K_MHC_20021_P  44.42   2         NA        NA        NA   \n",
      "2         42       Q1K_MHC_20042_P  30.97  NA          2         2        NA   \n",
      "3         43       Q1K_HSJ_10043_P  17.08   2        2,3       2,3         1   \n",
      "4         45      Q1K_HSJ_10043_F1  58.13   2          3         3         1   \n",
      "5         62       Q1K_HSJ_10062_P  40.77   1          3         3         1   \n",
      "..       ...                   ...    ...  ..        ...       ...       ...   \n",
      "64  525-1073   Q1K_HSJ_1525-1073_P  18.72   1        2,3       2,3         1   \n",
      "65  525-1083   Q1K_HSJ_1525-1083_P  15.15   2          2         2        NA   \n",
      "66  525-1109   Q1K_HSJ_1525-1109_P  14.01   2          2         2        NA   \n",
      "67  525-1110  Q1K_HSJ_1525-1109_M1  46.62   1          2         2        NA   \n",
      "68  525-1111  Q1K_HSJ_1525-1109_F1  48.01   2          1         1        NA   \n",
      "\n",
      "0      MR_date  \n",
      "1   2024-10-01  \n",
      "2   2024-08-09  \n",
      "3   2024-05-31  \n",
      "4   2024-05-31  \n",
      "5   2024-06-18  \n",
      "..         ...  \n",
      "64  2024-07-18  \n",
      "65  2025-03-05  \n",
      "66  2025-03-06  \n",
      "67  2025-03-06  \n",
      "68  2025-03-05  \n",
      "\n",
      "[68 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Piece together demographics for MR subs\n",
    "colRecordID=0\n",
    "colBirth1=2\n",
    "colBirth2=3\n",
    "colSex1=4\n",
    "colSex2=5\n",
    "colDiag=6\n",
    "colGen=7\n",
    "colMRdate=9\n",
    "\n",
    "dataAnalysis=np.array(['RecordID','SubID','Age','Sex','Diag_behav','Diag_gene','Gene_copy','MR_date'])\n",
    "\n",
    "for iSub in MRsubs:\n",
    "    #print(iSub)\n",
    "    subRows=dataDemClean[(dataDemClean[:,colRecordID] == iSub)] #find rows with data for that sub \n",
    "\n",
    "    Q1Kidx=(MRsubsInfo[:,colRecordID] == iSub)\n",
    "    Q1Kid=MRsubsInfo[Q1Kidx,1][0]\n",
    "    #print(Q1Kid)\n",
    "    \n",
    "    subBirth=[] #False\n",
    "    subSex=[] #False\n",
    "    subDiag_full=[] #False\n",
    "    subGen=[] #False\n",
    "    subMRdate=[]\n",
    "    for row in subRows:\n",
    "        #birth\n",
    "        if not subBirth and any(row[colBirth1]):\n",
    "            subBirth=row[colBirth1]\n",
    "        elif not subBirth and any(row[colBirth2]):\n",
    "            subBirth=row[colBirth2]\n",
    "      \n",
    "        #sex\n",
    "        if not subSex and any(row[colSex1]):\n",
    "            subSex=row[colSex1]\n",
    "        elif not subSex and any(row[colSex2]):\n",
    "            subSex=row[colSex2]\n",
    "\n",
    "        #diagnosis\n",
    "        if not subDiag_full and any(row[colDiag]):\n",
    "            subDiag_full=row[colDiag]\n",
    "        \n",
    "        #genetics\n",
    "        if not subGen and any(row[colGen]):\n",
    "            subGen=row[colGen]\n",
    "        \n",
    "        #MR info\n",
    "        if not subMRdate and any(row[colMRdate]):\n",
    "            subMRdate=row[colMRdate]\n",
    "   \n",
    "    subAge_long=relativedelta(datetime.strptime(subMRdate,\"%Y-%m-%d\"),datetime.strptime(subBirth,\"%Y-%m-%d\"))\n",
    "    subAge=round(subAge_long.years +subAge_long.months/12 + subAge_long.days/365.25,2)\n",
    "\n",
    "    if not subSex: #some are blank?\n",
    "        subSex='NA'\n",
    "    if not subDiag_full:\n",
    "        subDiag_full='NA'\n",
    "    if not subGen:\n",
    "        subGen='NA'\n",
    "\n",
    "    subData=np.array([iSub,Q1Kid,subAge,subSex,subDiag_full,subDiag_full,subGen,subMRdate])\n",
    "    dataAnalysis=np.vstack([dataAnalysis,subData])\n",
    "\n",
    "dataAnalysis_df=pd.DataFrame(dataAnalysis)\n",
    "dataAnalysis_df.columns=dataAnalysis_df.iloc[0] #turn first row into Header\n",
    "dataAnalysis_df=dataAnalysis_df[1:]\n",
    "print(dataAnalysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d13d7e9-65e3-447b-b916-d649d10c7116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   RecordID SubNumber SubCategory    Age     Sex Diagnosis_behav  \\\n",
      "1         21      0021           P  44.42    male              NA   \n",
      "2         42      0042           P  30.97      NA        affected   \n",
      "3         43      0043           P  17.08    male        affected   \n",
      "4         45      0043          F1  58.13    male         unknown   \n",
      "5         62      0062           P  40.77  female         unknown   \n",
      "..       ...       ...         ...    ...     ...             ...   \n",
      "64  525-1073      1073           P  18.72  female        affected   \n",
      "65  525-1083      1083           P  15.15    male        affected   \n",
      "66  525-1109      1109           P  14.01    male        affected   \n",
      "67  525-1110      1109          M1  46.62  female        affected   \n",
      "68  525-1111      1109          F1  48.01    male      unaffected   \n",
      "\n",
      "0  Diagnosis_gene  Genotype  \n",
      "1              NA   unknown  \n",
      "2         unknown   unknown  \n",
      "3         carrier  deletion  \n",
      "4         carrier  deletion  \n",
      "5         carrier  deletion  \n",
      "..            ...       ...  \n",
      "64        carrier  deletion  \n",
      "65        unknown   unknown  \n",
      "66        unknown   unknown  \n",
      "67        unknown   unknown  \n",
      "68    non-carrier   unknown  \n",
      "\n",
      "[68 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Decode/reformat responses \n",
    "allSubCats=['SubCategory']\n",
    "allSubIDs=['SubNumber']\n",
    "allSubSexes=['Sex']\n",
    "allSubDiag_beh=['Diagnosis_behav']\n",
    "allSubDiag_gen=['Diagnosis_gene']\n",
    "allSubGene=['Genotype']\n",
    "\n",
    "for row in dataAnalysis:\n",
    "    subSex=row[3]\n",
    "    subDiag=row[4]\n",
    "    subGene=row[6]\n",
    "\n",
    "    # Sex\n",
    "    if \"1\" in subSex:\n",
    "        allSubSexes.append('female')\n",
    "    elif \"2\" in subSex:\n",
    "        allSubSexes.append('male')\n",
    "    elif \"NA\" in subSex:\n",
    "        allSubSexes.append(subSex) #NA\n",
    "\n",
    "    # Diagnosis\n",
    "    subDiag_behav=\"unknown\"\n",
    "    subDiag_gene=\"unknown\"\n",
    "    if \"4\" in subDiag:\n",
    "        subDiag_behav='unknown_TBD' \n",
    "        subDiag_gene='unknown_TBD'\n",
    "    if \"1\" in subDiag: # or \"NA\" in subDiag:\n",
    "        subDiag_behav='unaffected' \n",
    "        subDiag_gene='non-carrier'\n",
    "    if \"2\" in subDiag:\n",
    "        subDiag_behav='affected'\n",
    "    if \"3\" in subDiag:\n",
    "        subDiag_gene='carrier'    \n",
    "    if \"NA\" in subDiag:\n",
    "        subDiag_behav='NA' \n",
    "        subDiag_gene='NA'\n",
    "    \n",
    "    if \"Diag\" not in subDiag: #only add if not first row\n",
    "        allSubDiag_beh.append(subDiag_behav)\n",
    "        allSubDiag_gen.append(subDiag_gene)\n",
    "\n",
    "    # Genetics\n",
    "    subGenetype=\"unknown\"\n",
    "    if \"1\" in subGene:\n",
    "        subGenetype='deletion'\n",
    "    if \"2\" in subGene:\n",
    "        subGenetype='duplication'\n",
    "    if \"Gene\" not in subGene: #only add if not first row\n",
    "        allSubGene.append(subGenetype)\n",
    "\n",
    "dataDecoded=np.vstack([dataAnalysis[:,0],np.hstack([allSubIDs,MRsubsInfo[:,3]]),np.hstack([allSubCats,MRsubsInfo[:,4]]),dataAnalysis[:,2],np.array(allSubSexes),np.array(allSubDiag_beh),np.array(allSubDiag_gen),np.array(allSubGene)]).T\n",
    "dataDecoded_df=pd.DataFrame(dataDecoded)\n",
    "dataDecoded_df.columns=dataDecoded_df.iloc[0]\n",
    "dataDecoded_df=dataDecoded_df[1:]\n",
    "print(dataDecoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "84be6e0d-807c-49f1-b61b-badda28c5d72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   RecordID SubNumber SubCategory    Age     Sex Diagnosis_behav  \\\n",
      "1         21      0021           P  44.42    male              NA   \n",
      "2         42      0042           P  30.97      NA        affected   \n",
      "3         43      0043           P  17.08    male        affected   \n",
      "4         45      0043          F1  58.13    male         unknown   \n",
      "5         62      0062           P  40.77  female         unknown   \n",
      "..       ...       ...         ...    ...     ...             ...   \n",
      "64  525-1073      1073           P  18.72  female        affected   \n",
      "65  525-1083      1083           P  15.15    male        affected   \n",
      "66  525-1109      1109           P  14.01    male        affected   \n",
      "67  525-1110      1109          M1  46.62  female        affected   \n",
      "68  525-1111      1109          F1  48.01    male      unaffected   \n",
      "\n",
      "0  Diagnosis_gene  Genotype b1_map(1) b1_map(2)           t1w_mprage  \\\n",
      "1              NA   unknown      Done      Done                 Done   \n",
      "2         unknown   unknown      Done      Done                 Done   \n",
      "3         carrier  deletion      Done      Done                 Done   \n",
      "4         carrier  deletion      Done      Done                 Done   \n",
      "5         carrier  deletion      Done      Done                 Done   \n",
      "..            ...       ...       ...       ...                  ...   \n",
      "64        carrier  deletion      Done      Done  Noticeable artifact   \n",
      "65        unknown   unknown      Done      Done                 Done   \n",
      "66        unknown   unknown      Done      Done                 Done   \n",
      "67        unknown   unknown      Done      Done                 Done   \n",
      "68    non-carrier   unknown      Done      Done                 Done   \n",
      "\n",
      "0  func-resting func-cloudy fmap-AP fmap-PA dwi_38dir_AP dwi_70dir_AP  \\\n",
      "1          Done        Done    Done    Done         Done         Done   \n",
      "2          Done        Done    Done    Done         Done         Done   \n",
      "3          Done        Done    Done    Done         Done         Done   \n",
      "4          Done        Done    Done    Done         Done         Done   \n",
      "5          Done        Done    Done    Done         Done         Done   \n",
      "..          ...         ...     ...     ...          ...          ...   \n",
      "64         Done        Done    Done    Done         Done         Done   \n",
      "65         Done        Done    Done    Done         Done         Done   \n",
      "66         Done        Done    Done    Done         Done         Done   \n",
      "67         Done        Done    Done    Done         Done         Done   \n",
      "68         Done        Done    Done    Done         Done         Done   \n",
      "\n",
      "0  dwi_b0_PA                   t1w_mp2rage Complete?  \n",
      "1       Done                          Done  Complete  \n",
      "2       Done                          Done  Complete  \n",
      "3       Done                          Done  Complete  \n",
      "4       Done                          Done  Complete  \n",
      "5       Done                          Done  Complete  \n",
      "..       ...                           ...       ...  \n",
      "64      Done                          Done  Complete  \n",
      "65      Done                          Done  Complete  \n",
      "66      Done                 Done,Repeated  Complete  \n",
      "67      Done  Repeated,Not done/incomplete  Complete  \n",
      "68      Done                          Done  Complete  \n",
      "\n",
      "[68 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add scan acquisition notes\n",
    "scanCols = list(range(6,17)) #where \"Done\" status for each scan is listed\n",
    "scanCols.append(29) #where the whole scan is marked as \"complete\"\n",
    "\n",
    "scanNames = dataAcqClean[0,scanCols]\n",
    "#print(scanNames)\n",
    "scansDecoded=np.hstack([dataDecoded,np.empty([len(dataDecoded),len(scanCols)])])\n",
    "\n",
    "for iSub in range(0,len(MRsubs)+1):\n",
    "    \n",
    "    if iSub == 0:\n",
    "        scansDecoded[iSub,-(len(scanCols)):]=scanNames #header\n",
    "    else:\n",
    "        dataRow = np.where(dataAcqClean[:, 0] == MRsubs[iSub-1])[0] \n",
    "        #print(MRsubs[iSub-1],': ', dataRow)\n",
    "        if dataRow: #if not empty (Record ID 265?)\n",
    "            scansDecoded[iSub,-(len(scanCols)):]=dataAcqClean[dataRow,scanCols]\n",
    "\n",
    "scansDecoded_df=pd.DataFrame(scansDecoded)\n",
    "scansDecoded_df.columns=scansDecoded_df.iloc[0]\n",
    "scansDecoded_df=scansDecoded_df[1:]\n",
    "print(scansDecoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0850db3c-8ac5-499e-98ac-1eed2a1510e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0     1   2                                                  3\n",
      "0       20021  0021   P  /data_/q1k/data//id20021/P/Q1K_MHC_20021_P_202...\n",
      "1       20042  0042   P  /data_/q1k/data//id20042/P/Q1K_MCH_20042_P_202...\n",
      "2       10043  0043   P  /data_/q1k/data//id10043/P/Q1K_HSJ_10043_P_202...\n",
      "3       10043  0043  F1  /data_/q1k/data//id10043/F1/Q1K_HSJ_10043_F1_2...\n",
      "4       10062  0062   P                  /data_/q1k/data//id10062/P/*Q1K*/\n",
      "..        ...   ...  ..                                                ...\n",
      "64  1525_1073  1073   P  /data_/q1k/data//id1525_1073/P/Q1K_HSJ_1525_10...\n",
      "65  1525_1083  1083   P  /data_/q1k/data//id1525_1083/P/Q1K_HSJ_1525_10...\n",
      "66  1525_1109  1109   P  /data_/q1k/data//id1525_1109/P/Q1K_HSJ_1525_11...\n",
      "67  1525_1109  1109  M1  /data_/q1k/data//id1525_1109/M1/Q1K_HSJ_1525_1...\n",
      "68  1525_1109  1109  F1  /data_/q1k/data//id1525_1109/F1/Q1K_HSJ_1525_1...\n",
      "\n",
      "[69 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Read in list of BIC Dicom Files\n",
    "data_temp=[] \n",
    "with open(filePathBIC,newline='') as BIClookupFile:\n",
    "    rawDataBIC=csv.reader(BIClookupFile,delimiter=',')\n",
    "    for row in rawDataBIC:   \n",
    "        data_temp.append(row)\n",
    "        \n",
    "dataBIC_temp=np.array(data_temp) \n",
    "dataBIC=dataBIC_temp[dataBIC_temp[:,1].argsort()] #sort by subID\n",
    "dataBIC_df=pd.DataFrame(dataBIC)\n",
    "print(dataBIC_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae334e88-a2a4-4ab1-ac7d-b1b0d6708773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   RecordID SubNumber SubCategory    Age     Sex Diagnosis_behav  \\\n",
      "1         21      0021           P  44.42    male              NA   \n",
      "2         42      0042           P  30.97      NA        affected   \n",
      "3         43      0043           P  17.08    male        affected   \n",
      "4         45      0043          F1  58.13    male         unknown   \n",
      "5         62      0062           P  40.77  female         unknown   \n",
      "..       ...       ...         ...    ...     ...             ...   \n",
      "64  525-1073      1073           P  18.72  female        affected   \n",
      "65  525-1083      1083           P  15.15    male        affected   \n",
      "66  525-1109      1109           P  14.01    male        affected   \n",
      "67  525-1110      1109          M1  46.62  female        affected   \n",
      "68  525-1111      1109          F1  48.01    male      unaffected   \n",
      "\n",
      "0  Diagnosis_gene  Genotype b1_map(1) b1_map(2)  ... func-resting func-cloudy  \\\n",
      "1              NA   unknown      Done      Done  ...         Done        Done   \n",
      "2         unknown   unknown      Done      Done  ...         Done        Done   \n",
      "3         carrier  deletion      Done      Done  ...         Done        Done   \n",
      "4         carrier  deletion      Done      Done  ...         Done        Done   \n",
      "5         carrier  deletion      Done      Done  ...         Done        Done   \n",
      "..            ...       ...       ...       ...  ...          ...         ...   \n",
      "64        carrier  deletion      Done      Done  ...         Done        Done   \n",
      "65        unknown   unknown      Done      Done  ...         Done        Done   \n",
      "66        unknown   unknown      Done      Done  ...         Done        Done   \n",
      "67        unknown   unknown      Done      Done  ...         Done        Done   \n",
      "68    non-carrier   unknown      Done      Done  ...         Done        Done   \n",
      "\n",
      "0  fmap-AP fmap-PA dwi_38dir_AP dwi_70dir_AP dwi_b0_PA  \\\n",
      "1     Done    Done         Done         Done      Done   \n",
      "2     Done    Done         Done         Done      Done   \n",
      "3     Done    Done         Done         Done      Done   \n",
      "4     Done    Done         Done         Done      Done   \n",
      "5     Done    Done         Done         Done      Done   \n",
      "..     ...     ...          ...          ...       ...   \n",
      "64    Done    Done         Done         Done      Done   \n",
      "65    Done    Done         Done         Done      Done   \n",
      "66    Done    Done         Done         Done      Done   \n",
      "67    Done    Done         Done         Done      Done   \n",
      "68    Done    Done         Done         Done      Done   \n",
      "\n",
      "0                    t1w_mp2rage Complete?  \\\n",
      "1                           Done  Complete   \n",
      "2                           Done  Complete   \n",
      "3                           Done  Complete   \n",
      "4                           Done  Complete   \n",
      "5                           Done  Complete   \n",
      "..                           ...       ...   \n",
      "64                          Done  Complete   \n",
      "65                          Done  Complete   \n",
      "66                 Done,Repeated  Complete   \n",
      "67  Repeated,Not done/incomplete  Complete   \n",
      "68                          Done  Complete   \n",
      "\n",
      "0                                       BIC_DICOM_dir  \n",
      "1   /data_/q1k/data//id20021/P/Q1K_MHC_20021_P_202...  \n",
      "2   /data_/q1k/data//id20042/P/Q1K_MCH_20042_P_202...  \n",
      "3   /data_/q1k/data//id10043/P/Q1K_HSJ_10043_P_202...  \n",
      "4   /data_/q1k/data//id10043/F1/Q1K_HSJ_10043_F1_2...  \n",
      "5                   /data_/q1k/data//id10062/P/*Q1K*/  \n",
      "..                                                ...  \n",
      "64  /data_/q1k/data//id1525_1073/P/Q1K_HSJ_1525_10...  \n",
      "65  /data_/q1k/data//id1525_1083/P/Q1K_HSJ_1525_10...  \n",
      "66  /data_/q1k/data//id1525_1109/P/Q1K_HSJ_1525_11...  \n",
      "67  /data_/q1k/data//id1525_1109/M1/Q1K_HSJ_1525_1...  \n",
      "68                                                0.0  \n",
      "\n",
      "[68 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#Compare REDCap subs with BIC Dicom Files\n",
    "scansDecoded_BIC=np.hstack([scansDecoded,np.empty([len(scansDecoded),1])])\n",
    "\n",
    "for iSub in range(0,len(dataBIC)):\n",
    "    \n",
    "    if iSub == 0:\n",
    "        scansDecoded_BIC[iSub,-1]='BIC_DICOM_dir' #header\n",
    "    else:\n",
    "        subID = dataBIC[iSub-1,1]\n",
    "        subCat = dataBIC[iSub-1,2]\n",
    "        subDicomDir = dataBIC[iSub-1,3]\n",
    "\n",
    "        # Add Dicom dir to corresponding row [translated from chatgpt)\n",
    "        subIdx1 = np.where(scansDecoded_BIC[:, 1] == subID)  \n",
    "        subIdx2 = np.where(scansDecoded_BIC[:, 2] == subCat) \n",
    "        dataRow = np.intersect1d(subIdx1,subIdx2)\n",
    "        scansDecoded_BIC[dataRow,-1]=subDicomDir\n",
    "        \n",
    "# Check for missing scans -- NOTE: FIX THIS?\n",
    "missingSubs=[]\n",
    "for iSub in range(1,len(scansDecoded_BIC)):\n",
    "    subRow = scansDecoded_BIC[iSub,:]\n",
    "\n",
    "    # Add known errors/incomplete scans\n",
    "    if '0255' in subRow[1] and 'M1' in subRow[2]:\n",
    "        scansDecoded_BIC[iSub,-1]='No MR data collected' # participant pulled out right after AAscout\n",
    "    elif '0265' in subRow[1] and 'P' in subRow[2]:\n",
    "        scansDecoded_BIC[iSub,-1]='No MR data collected' # participant did not fit head coil     \n",
    "\n",
    "    if not scansDecoded_BIC[iSub,-1]:\n",
    "        missingSubs.append(scansDecoded_BIC[iSub,1]+scansDecoded_BIC[iSub,2])\n",
    "        #print('REDCap subs without BIC scans: ', scansDecoded_BIC[iSub,1])\n",
    "        \n",
    "scansDecoded_BIC_df=pd.DataFrame(scansDecoded_BIC)\n",
    "scansDecoded_BIC_df.columns=scansDecoded_BIC_df.iloc[0]\n",
    "scansDecoded_BIC_df=scansDecoded_BIC_df[1:]\n",
    "print(scansDecoded_BIC_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7daf565-aba8-4fdc-9022-e063e37214d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDCap subs without BIC scans:  ['1109F1']\n"
     ]
    }
   ],
   "source": [
    "# Output missing scans, if any\n",
    "if missingSubs:\n",
    "    print('REDCap subs without BIC scans: ', missingSubs)\n",
    "else:\n",
    "    print('All REDCap subs have BIC scans accounted for!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439635ce-8523-45d2-b8b7-05060ab98f74",
   "metadata": {},
   "source": [
    "## RUN DESCRIPTIVE STATS\n",
    "Aggregate number of usable scans, participant demographics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49ee57d9-30df-48d2-b9d4-01cb0890e3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subs without usable scan data: ['0255F1' '0255M1' '0265P']\n",
      "Total # of subs with partial data: 65\n",
      "Subs with partial scan data: ['0064M1' '0181P' '0231S1']\n",
      "Total # of subs with complete data: 62\n"
     ]
    }
   ],
   "source": [
    "# Run stats\n",
    "\n",
    "doneRows = list(range(8, 19))  \n",
    "removeIncompleteSubs = []\n",
    "for iSub in range(1, len(scansDecoded_BIC)):  \n",
    "    testCols = scansDecoded_BIC[iSub, doneRows]\n",
    "    #print(iSub,' testCols:',testCols)\n",
    "    if (testCols == 'Done').sum() > 2:\n",
    "        continue\n",
    "    else:\n",
    "        removeIncompleteSubs.append(iSub)\n",
    "incompleteIDs= [sub-1 for sub in removeIncompleteSubs] #since MRsubsInfo index starts at 0\n",
    "print('Subs without usable scan data:',MRsubsInfo[incompleteIDs,3]+MRsubsInfo[incompleteIDs,4])\n",
    "\n",
    "# Remove incomplete subs\n",
    "attemptedData = np.delete(scansDecoded_BIC,removeIncompleteSubs,axis=0)\n",
    "print('Total # of subs with partial data:',len(attemptedData)-1) #subtract header row\n",
    "#print(pd.DataFrame(attemptedData))\n",
    "\n",
    "removePartialSubs = []\n",
    "for iSub in range(1, len(attemptedData)):  \n",
    "    testCols = attemptedData[iSub, doneRows]\n",
    "    if any(testCols == 'Not done/incomplete') or any(testCols == ''):\n",
    "        removePartialSubs.append(iSub)\n",
    "partialIDs= [sub-1 for sub in removePartialSubs] #since MRsubsInfo index starts at 0\n",
    "print('Subs with partial scan data:',MRsubsInfo[partialIDs,3]+MRsubsInfo[partialIDs,4])\n",
    "\n",
    "# Remove partial subs        \n",
    "completedData = np.delete(attemptedData,removePartialSubs,axis=0)\n",
    "print('Total # of subs with complete data:',len(completedData)-1) #subtract header row\n",
    "#print(pd.DataFrame(completedData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1ab94501-8c06-4a03-a315-3a181742494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan counts (Total N = 65 ):\n",
      "              Total\n",
      "b1_map(1)        65\n",
      "b1_map(2)        65\n",
      "t1w_mprage       65\n",
      "func-resting     64\n",
      "func-cloudy      64\n",
      "fmap-AP          64\n",
      "fmap-PA          64\n",
      "dwi_38dir_AP     65\n",
      "dwi_70dir_AP     63\n",
      "dwi_b0_PA        63\n",
      "t1w_mp2rage      61\n"
     ]
    }
   ],
   "source": [
    "# Count how many subs completed each scan\n",
    "scanHeaders = attemptedData[0,doneRows]\n",
    "scanData = pd.DataFrame(columns=['Total']) #(columns=scanHeaders)\n",
    "\n",
    "for iScan in range(0,len(scanHeaders)):\n",
    "    n=0\n",
    "    for iSub in range(1,len(attemptedData)):\n",
    "        if 'Not done/incomplete' in attemptedData[iSub,doneRows[iScan]] or not attemptedData[iSub,doneRows[iScan]]:\n",
    "            continue\n",
    "        else:\n",
    "            n+=1\n",
    "    scanData.loc[scanHeaders[iScan]]=n\n",
    "    \n",
    "print('Scan counts (Total N =',len(attemptedData)-1,'):')    \n",
    "print(scanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8d039c07-8459-4b53-a71a-5f3efcd6aea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Count Age_Mean      Age_Range Sex_Female Sex_Male Sex_Other  \\\n",
      "P        23    19.81  [9.98, 44.42]         13        9         1   \n",
      "M1       18    45.14  [34.98, 60.6]         18        0         0   \n",
      "F1       12    46.95  [32.95, 60.8]          0       12         0   \n",
      "S*       12    15.58   [9.89, 29.7]          5        7         0   \n",
      "Total    65    31.05   [9.89, 60.8]         36       28         1   \n",
      "\n",
      "      NDD_Affected NDD_NotAffected NDD_Unknown  \n",
      "P               18               0           5  \n",
      "M1               4               8           6  \n",
      "F1               0               7           5  \n",
      "S*               6               2           4  \n",
      "Total           28              17          20  \n"
     ]
    }
   ],
   "source": [
    "# Aggregate demographics\n",
    "demogHeaders=['Count','Age_Mean','Age_Range','Sex_Female','Sex_Male','Sex_Other','NDD_Affected','NDD_NotAffected','NDD_Unknown']\n",
    "demogRows=['P','M1','F1','S*','Total']\n",
    "demogData=pd.DataFrame(columns=demogHeaders)\n",
    "\n",
    "catCol=attemptedData[1:,2]\n",
    "ageCol=attemptedData[1:,3]\n",
    "sexCol=attemptedData[1:,4]\n",
    "NDDcol=attemptedData[1:,5]\n",
    "\n",
    "for iRow in demogRows:\n",
    "\n",
    "    if 'Total' in iRow:\n",
    "        rowIdx = list(range(0,len(attemptedData)-1))\n",
    "    elif 'S' in iRow:\n",
    "        rowIdx1 = np.where(catCol == 'S1')[0]\n",
    "        rowIdx2 = np.where(catCol == 'S2')[0]\n",
    "        rowIdx3 = np.where(catCol == 'S3')[0]\n",
    "        rowIdx4 = np.where(catCol == 'S4')[0]\n",
    "        rowIdx = np.concatenate([rowIdx1,rowIdx2,rowIdx3,rowIdx4])\n",
    "    else:\n",
    "        rowIdx = np.where(catCol == iRow)[0]   \n",
    "    \n",
    "    #Total    \n",
    "    catTotal=len(rowIdx)\n",
    "    demogData.loc[iRow,'Count'] = catTotal\n",
    "\n",
    "    #Age\n",
    "    currAges_temp=ageCol[rowIdx]\n",
    "    currAges=[float(age) for age in currAges_temp]\n",
    "    ages_mean=round(statistics.mean(currAges),2)\n",
    "    ages_min=min(currAges)\n",
    "    ages_max=max(currAges)\n",
    "\n",
    "    demogData.loc[iRow,'Age_Mean'] = ages_mean\n",
    "    demogData.loc[iRow,'Age_Range'] = [ages_min, ages_max]\n",
    "\n",
    "    #Sex\n",
    "    currSexes=sexCol[rowIdx]\n",
    "    count_fem=0\n",
    "    count_mal=0\n",
    "    count_oth=0\n",
    "    for iSex in currSexes:\n",
    "        if 'female' in iSex:\n",
    "            count_fem+=1 \n",
    "        elif 'male' in iSex:\n",
    "            count_mal+=1\n",
    "        elif 'NA' in iSex:\n",
    "            count_oth+=1\n",
    "\n",
    "    demogData.loc[iRow,'Sex_Female'] = count_fem\n",
    "    demogData.loc[iRow,'Sex_Male'] = count_mal\n",
    "    demogData.loc[iRow,'Sex_Other'] = count_oth\n",
    "\n",
    "    #NDD\n",
    "    currNDDs=NDDcol[rowIdx]\n",
    "    count_aff=0\n",
    "    count_not=0\n",
    "    count_NA=0\n",
    "    for iNDD in currNDDs:\n",
    "        if iNDD == 'affected':\n",
    "            count_aff+=1 \n",
    "        elif iNDD == 'unaffected':\n",
    "            count_not+=1\n",
    "        elif 'NA' in iNDD or 'unknown' in iNDD:\n",
    "            count_NA+=1\n",
    "\n",
    "    demogData.loc[iRow,'NDD_Affected'] = count_aff\n",
    "    demogData.loc[iRow,'NDD_NotAffected'] = count_not\n",
    "    demogData.loc[iRow,'NDD_Unknown'] = count_NA\n",
    "\n",
    "    \n",
    "print(demogData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
